# -*- coding: utf-8 -*-
"""
Created on Sat Mar 26 18:39:12 2022

@author: Tim Schommer
"""
import os.path
import pandas as pd
from tqdm import tqdm
from subprocess import Popen, PIPE
from Utilities.global_names import process_temp, resources, node2vec
from Utilities.program_vars import algorithms_index, joint_index

doFullCheck = True

feature_dims = 20
feature_epochs = 1
check_existing = True


def validateSolo(data):
    if "feature_dims" in data:
        val = data["feature_dims"]
        if type(val) is not int or val <= 0:
            raise AttributeError("The field 'feature_dims' must be an "
                 "integer greater than 0")
    if "feature_epochs" in data:
        val = data["feature_epochs"]
        if type(val) is not int or val <= 0:
            raise AttributeError("The field 'feature_epochs' must be an "
                 "integer greater than 0")
    if "check_existing" in data and type(data["check_existing"]) is not bool:
        raise AttributeError("The field 'check_existing' must be a "
                 "bool.")



def get_features_nodes(
    graph,
    data,
    tempdir_name
):
    """ Generate node2vec features for the nodes in a graph

    Parameters
    ----------
    graph : networkx graph
        The graph we run node2vec on.
    dims : int, optional
        Specifies the number of dimensions to pass to node2vec[1]. Default: 20
    epochs : int, optional
        Specifies the number of epochs to run the node2vec for. Default: 1
    node2vec_path : str, optional
        Path to the node2vec executable. Default: "node2vec", which means that it is
        in one folder with this file
    tempdir_name : str, optional
        The name of a temporary directory to use for running node2vec.
        Default: "temp_dir"
    dataset_name : str, optional
        The name of the dataset, used when naming the files in the temporary directory.
        Default: "facebook"
    check_existing : boolean, optional
        Determines if we are checking for an alredy existing algorithm output in the
        temporary directory.


    Returns
    -------
    df_emb : pd.DataFrame
        A dataframe with the contents of embeddings generated by node2vec. It is also
        available as <dataset_name>-d<dims>.emb in the temporary directory.

    References
    ----------
    .. [1] Grover, Aditya, and Jure Leskovec. "node2vec: Scalable feature learning for networks."
        Proceedings of the 22nd ACM SIGKDD international conference on
        Knowledge discovery and data mining. 2016.

    """
    if not os.path.exists(tempdir_name):
        os.makedirs(tempdir_name,exist_ok=True)

    check_existing = data.get(algorithms_index,"check_existing")
    dims = data.get(algorithms_index,"feature_dims")
    epochs = data.get(algorithms_index,"feature_epochs")
    FNAME_IN = os.path.join(tempdir_name, "edges.edgelist")
    FNAME_OUT = os.path.join(tempdir_name, f"d{dims}-d{epochs}.emb")

    # Checking if we already ran the function before
    if check_existing and os.path.exists(FNAME_OUT):
        return pd.read_csv(
            FNAME_OUT,
            sep=" ",
            names=(["node"] + [f"feat_{i}" for i in range(dims)]),
            skiprows=1,
        )
    # Saving the edgelist to run node2vec on
    graph.write_edgelist(FNAME_IN)
    #TODO node2vec.exe won't run for me
    # Preparing to run node2vec
    node2vec_path = os.path.join(resources, node2vec)
    process = Popen(
        [
            node2vec_path,
            f"-i:{FNAME_IN}",
            f"-o:{FNAME_OUT}",
            f"-d:{dims}",
            f"-e:{epochs}",
            "-v",
        ],
        shell=True,
        stdout=PIPE,
        stderr=PIPE,
    )
    (output, err) = process.communicate()
    _ = process.wait()  # Returns exit code

    return pd.read_csv(
        FNAME_OUT,
        sep=" ",
        names=(["node"] + [f"feat_{i}" for i in range(dims)]),
        skiprows=1,
    )


def generate_node2vec_fetures(
    graph,
    data,
    tempdir_name
):
    
    # Checking if we did this before
    df = graph.toDataframeEdges()[["source", "target"]]
    check_existing = data.get(algorithms_index,"check_existing")
    num_features = data.get(algorithms_index,"feature_dims")
    epochs = data.get(algorithms_index,"feature_epochs")
    FNAME_SAVE = os.path.join(tempdir_name, f"d{num_features}-d{epochs}-edges.emb")
    if check_existing and os.path.exists(FNAME_SAVE):
        df_ret = pd.read_csv(FNAME_SAVE)
        df_ret[df_ret.columns[0]] = df_ret[df_ret.columns[0]].astype(int)
        return df_ret.set_index(df_ret.columns[0])

    # Getting node embeddings
    
    df_emb = get_features_nodes(
        graph
        ,data
        ,tempdir_name
    )
    df_emb = df_emb.set_index("node").sort_values(by="node")

    # Generating edge features
    df_feats = []
    for row in tqdm(df.itertuples(), total=df.shape[0]):
        df_feats.append(df_emb.loc[row.source].values * df_emb.loc[row.target].values)
    df_feats = pd.DataFrame(df_feats)

    # Saving the results
    df_feats.to_csv(FNAME_SAVE)

    return df_feats


def validateFull(data, application, algorighm):
    startPath = os.path.join(process_temp, application.networkPath(),
                 "imlinucb")
    features = generate_node2vec_fetures(application, data, startPath)
    data.setAttr(joint_index, "features", features)
    